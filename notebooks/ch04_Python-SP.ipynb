{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IcGWAI1_1GQ"
      },
      "source": [
        "# 第4章 Python による音声信号処理\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/r9y9/ttslearn/blob/master/notebooks/ch04_Python-SP.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGSPAVpT_1GU"
      },
      "source": [
        "## 4.1 準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quv7fnpH_1GV"
      },
      "source": [
        "### Python version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "koFG88QA_1GV",
        "outputId": "2568a7fa-d36c-43fa-9007-5f4591376aab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "!python -VV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djc9SHv1_1GV"
      },
      "source": [
        "### ttslearn のインストール"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-7XBemY_1GV"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "try:\n",
        "    import ttslearn\n",
        "except ImportError:\n",
        "    !pip install ttslearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_ylCgKv_1GW"
      },
      "outputs": [],
      "source": [
        "import ttslearn\n",
        "ttslearn.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjjUEP-z_1GW"
      },
      "source": [
        "### ttslearn の動作確認"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOPYgxvX_1GW"
      },
      "outputs": [],
      "source": [
        "from ttslearn.dnntts import DNNTTS\n",
        "from IPython.display import Audio\n",
        "\n",
        "engine = DNNTTS()\n",
        "wav, sr = engine.tts(\"日本語音声合成のデモです。\")\n",
        "Audio(wav, rate=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmCw7KVI_1GW"
      },
      "outputs": [],
      "source": [
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8,2))\n",
        "librosa.display.waveshow(wav.astype(np.float32), sr, ax=ax)\n",
        "ax.set_xlabel(\"Time [sec]\")\n",
        "ax.set_ylabel(\"Amplitude\")\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUwggtDU_1GW"
      },
      "source": [
        "### パッケージのインポート"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aY78PIfj_1GW"
      },
      "outputs": [],
      "source": [
        "%pylab inline\n",
        "%load_ext autoreload\n",
        "%autoreload\n",
        "import IPython\n",
        "from IPython.display import Audio\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrUBrMTg_1GW"
      },
      "outputs": [],
      "source": [
        "# シードの固定\n",
        "from ttslearn.util import init_seed\n",
        "init_seed(1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad5P5Mfr_1GW"
      },
      "source": [
        "### 描画周りの設定"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JZ8OUoo_1GW"
      },
      "outputs": [],
      "source": [
        "from ttslearn.notebook import get_cmap, init_plot_style, savefig\n",
        "cmap = get_cmap()\n",
        "init_plot_style()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZtuJwQH_1GX"
      },
      "source": [
        "## 4.2 数値計算のためのPythonライブラリ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp0S96NH_1GX"
      },
      "source": [
        "### NumPy と Torch を用いた配列の作成"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-vpB-wb_1GX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VD61DeyL_1GX"
      },
      "outputs": [],
      "source": [
        "x = np.zeros((2,2), dtype=np.float32)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVyGtkHP_1GX"
      },
      "outputs": [],
      "source": [
        "y = torch.zeros(2,2, dtype=torch.float)\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_Ip0vX-_1GX"
      },
      "outputs": [],
      "source": [
        "type(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QAPtpu5_1GX"
      },
      "outputs": [],
      "source": [
        "type(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KazMFkUS_1GX"
      },
      "source": [
        "### numpy.ndarray と torch.Tensor のインタフェースの違い"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6nudpkd_1GX"
      },
      "outputs": [],
      "source": [
        "# Numpy では配列のサイズを tuple で与えます\n",
        "x = np.zeros((1,2,3), dtype=np.float32)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIeRB0Wx_1GX"
      },
      "outputs": [],
      "source": [
        "# PyTorch では配列のサイズを別々の引数で与えられます\n",
        "y = torch.zeros(1, 2, 3, dtype=torch.float32)\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2r3sMf8_1GX"
      },
      "outputs": [],
      "source": [
        "x.shape == y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcHbS1Uo_1GX"
      },
      "source": [
        "### numpy.ndarray と torch.Tensor の相互変換"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCOSqi-k_1GX"
      },
      "outputs": [],
      "source": [
        "x = np.zeros((2,2), dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HbEx3BN_1GX"
      },
      "outputs": [],
      "source": [
        "y = torch.zeros((2,2), dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WNKT14Bk_1GX"
      },
      "outputs": [],
      "source": [
        "# torch.Tensor から numpy.ndarray への変換\n",
        "type(y.numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TvGqGuFM_1GX"
      },
      "outputs": [],
      "source": [
        "# numpy.ndarray から torch.Tensor への変換\n",
        "type(torch.from_numpy(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoW7sUJg_1GX"
      },
      "source": [
        "### numpy.ndarray と torch.Tensor のメモリ共有"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9rHOHp3T_1GX"
      },
      "outputs": [],
      "source": [
        "x = np.zeros((2,2), dtype=np.float32)\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYyjoi1b_1GX"
      },
      "outputs": [],
      "source": [
        "y = torch.from_numpy(x)\n",
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTY5gEXr_1GX"
      },
      "outputs": [],
      "source": [
        "x[0,0] = 1.0 # メモリが共有されているため、 x への変更は y にも反映されます"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1PHz7Lw_1GX"
      },
      "outputs": [],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_NF1yFi_1GX"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G92KUeFz_1GY"
      },
      "source": [
        "## 4.3 音声ファイルの読み込み"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNxv0Ssn_1GY"
      },
      "source": [
        "### scipy.io.wavfile を利用した音声ファイルの読み込み"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0dLfI87l_1Ga"
      },
      "outputs": [],
      "source": [
        "from scipy.io import wavfile\n",
        "import ttslearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bvt52wYY_1Ga"
      },
      "outputs": [],
      "source": [
        "sr, wav = wavfile.read(ttslearn.util.example_audio_file())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7HTyhiX_1Ga"
      },
      "outputs": [],
      "source": [
        "sr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSaozuP2_1Ga"
      },
      "outputs": [],
      "source": [
        "wav.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KEs4STll_1Ga"
      },
      "outputs": [],
      "source": [
        "len(wav) / sr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fA8-aAyq_1Ga"
      },
      "outputs": [],
      "source": [
        "wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTGyUnW-_1Ga"
      },
      "outputs": [],
      "source": [
        "type(wav)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgr9Fjyq_1Ga"
      },
      "source": [
        "### 音声の可視化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWMPCLE3_1Ga"
      },
      "outputs": [],
      "source": [
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 音声ファイルの読み込み\n",
        "sr, x = wavfile.read(ttslearn.util.example_audio_file())\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8,2))\n",
        "librosa.display.waveshow(x.astype(np.float32), sr, ax=ax)\n",
        "\n",
        "ax.set_xlabel(\"Time [sec]\")\n",
        "ax.set_ylabel(\"Amplitude\")\n",
        "plt.tight_layout()\n",
        "\n",
        "# 図4-2\n",
        "savefig(\"fig/pyssp_waveshow\")\n",
        "\n",
        "# オーディオプレイヤーの表示\n",
        "Audio(x.astype(np.float32), rate=sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QKGa5GC_1Ga"
      },
      "source": [
        "## 4.4 音声のフーリエ変換"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-5tHCDf_1Ga"
      },
      "outputs": [],
      "source": [
        "# 音声ファイルの読み込み\n",
        "sr, x = wavfile.read(ttslearn.util.example_audio_file())\n",
        "# 振幅スペクトル\n",
        "X = np.abs(np.fft.rfft(x))\n",
        "# 対数振幅スペクトル\n",
        "logX = 20*np.log10(X)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(10, 4), sharex=True)\n",
        "freq = np.arange(len(X)) / 2 / len(X) * sr\n",
        "ax[0].plot(freq, X)\n",
        "ax[0].set_title(\"Amplitude spectrum\")\n",
        "ax[0].set_xlim(0, sr // 2)\n",
        "ax[0].set_xlabel(\"Frequency [Hz]\")\n",
        "ax[0].set_ylabel(\"Amplitude\")\n",
        "\n",
        "ax[1].plot(freq, logX)\n",
        "ax[1].set_title(\"Log amplitude spectrum\")\n",
        "ax[1].set_xlabel(\"Frequency [Hz]\")\n",
        "ax[1].set_ylabel(\"Amplitude [dB]\")\n",
        "plt.tight_layout()\n",
        "\n",
        "# 図4-3\n",
        "savefig(\"fig/pyssp_rfftplot\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0pzmll5_1Ga"
      },
      "source": [
        "## 4.5 音声の短時間フーリエ変換とその逆変換"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieYXE4Pk_1Gb"
      },
      "source": [
        "### 窓関数"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pkuhdwbj_1Gb"
      },
      "outputs": [],
      "source": [
        "N = 1024\n",
        "n = np.arange(N)\n",
        "w = 0.5 - 0.5 * np.cos(2*np.pi * n / N)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(6,4))\n",
        "ax.plot(w)\n",
        "ax.set_xlim(0, N)\n",
        "ax.set_xlabel(\"Time [sample]\")\n",
        "ax.set_ylabel(\"Amplitude\")\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqUusmEt_1Gb"
      },
      "source": [
        "### 短時間フーリエ変換の実装"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDhvnrT1_1Gb"
      },
      "outputs": [],
      "source": [
        "def hanning(N):\n",
        "    n = np.arange(N)\n",
        "    w = 0.5 - 0.5 * np.cos(2*np.pi * n / N)\n",
        "    return w\n",
        "\n",
        "def stft(x, N, S):\n",
        "    # 窓関数（簡単のため、窓幅とフレーム長 N は同じとします）\n",
        "    w = hanning(N)\n",
        "    # 短時間フーリエ変換のフレーム数\n",
        "    M = (len(x) - N) // S + 1\n",
        "    # 短時間フーリエ変換の結果格納用の 2 次元配列\n",
        "    X = np.zeros((M, N//2 + 1), dtype=complex)\n",
        "    # 音声をずらして切り出し、フーリエ変換\n",
        "    for m in range(M):\n",
        "        x_m = w * x[m*S:m*S+N]\n",
        "        X[m, :] = np.fft.rfft(x_m)\n",
        "    return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaZhUa5L_1Gb"
      },
      "source": [
        "### 短時間フーリエ変換の結果の可視化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laKO3R5g_1Gb"
      },
      "outputs": [],
      "source": [
        "# 音声ファイルの読み込み\n",
        "sr, x = wavfile.read(ttslearn.util.example_audio_file())\n",
        "\n",
        "# 5 ミリ秒のフレームシフトを考えます\n",
        "frame_shift = int(sr * 0.005)\n",
        "n_fft = 2048\n",
        "# スペクトログラム\n",
        "X = stft(x.astype(np.float32), n_fft, frame_shift)\n",
        "# 対数振幅に変換\n",
        "logX = librosa.amplitude_to_db(np.abs(X), ref=np.max)\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8,4), sharex=True)\n",
        "img = librosa.display.specshow(logX.T, hop_length=frame_shift, sr=sr, cmap=cmap, x_axis=\"time\", y_axis=\"hz\", ax=ax)\n",
        "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
        "# 音声のパワーは低域に集中するため、8000 Hz までを表示する\n",
        "ax.set_ylim(0, 8000)\n",
        "\n",
        "ax.set_xlabel(\"Time [sec]\")\n",
        "ax.set_ylabel(\"Frequency [Hz]\")\n",
        "plt.tight_layout()\n",
        "\n",
        "# 図4-5\n",
        "savefig(\"fig/pyssp_stft_example\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okxXcUcX_1Gb"
      },
      "source": [
        "### librosa.stft を用いた短時間フーリエ変換\n",
        "\n",
        "librosa.stftは、STFTを実行する前にデフォルトで信号の冒頭と末尾にパディング処理を行います。前述のSTFT実装はこの処理をサポートしていないため、同等のSTFTの結果を得るためには、center=Falseとしてパディング処理を行わないように設定します。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMCXUnIU_1Gb"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "\n",
        "# n_fft: 2048, frame_shift: 240\n",
        "X = librosa.stft(x.astype(np.float32), n_fft=n_fft, win_length=n_fft, hop_length=frame_shift, window=\"hann\", center=False).T\n",
        "# 対数振幅に変換\n",
        "logX = librosa.amplitude_to_db(np.abs(X), ref=np.max)\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(8,4), sharex=True)\n",
        "img = librosa.display.specshow(logX.T, hop_length=frame_shift, sr=sr, cmap=cmap, x_axis=\"time\", y_axis=\"hz\", ax=ax)\n",
        "fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
        "# 音声のパワーは低域に集中するため、8000 Hz までを表示する\n",
        "ax.set_ylim(0, 8000)\n",
        "\n",
        "ax.set_xlabel(\"Time [sec]\")\n",
        "ax.set_ylabel(\"Frequency [Hz]\")\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DlUYjbD_1Gb"
      },
      "source": [
        "### 時間解像度と周波数解像度のトレードオフ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPDjd9EH_1Gb"
      },
      "outputs": [],
      "source": [
        "def next_power_of_2(x):\n",
        "    return 1 if x == 0 else 2**(x - 1).bit_length()\n",
        "\n",
        "fig, ax = plt.subplots(1, 3, figsize=(10,5), sharex=True, sharey=True)\n",
        "\n",
        "for idx, win_length_ms in enumerate([0.05, 0.02, 0.01]):\n",
        "    win_length = int(sr * win_length_ms)\n",
        "    frame_shift = win_length // 4\n",
        "    n_fft = next_power_of_2(win_length)\n",
        "\n",
        "    X = librosa.stft(x.astype(np.float32), n_fft=n_fft, win_length=n_fft, hop_length=frame_shift).T\n",
        "    logX =  librosa.amplitude_to_db(np.abs(X), ref=np.max)\n",
        "    mesh = librosa.display.specshow(\n",
        "        logX.T, hop_length=frame_shift, sr=sr, cmap=cmap, x_axis=\"time\", y_axis=\"hz\", ax=ax[idx])\n",
        "    fig.colorbar(mesh, ax=ax[idx], format=\"%+2.f dB\")\n",
        "    ax[idx].set_title(f\"win_length: {win_length}\")\n",
        "    mesh.set_clim(-80, 0)\n",
        "    ax[idx].set_xlim(1.0, 1.5)\n",
        "    ax[idx].set_xticks([1.0, 1.25, 1.5])\n",
        "    # あとでラベルを付け直すので、ここでは消しておく\n",
        "    ax[idx].set_ylabel(\"\")\n",
        "\n",
        "ax[0].set_ylabel(\"Frequency [Hz]\")\n",
        "for a in ax:\n",
        "    a.set_xlabel(\"Time [sec]\")\n",
        "    a.set_ylim(0, 8000)\n",
        "    a.xaxis.set_major_formatter(FormatStrFormatter('%.1f'))\n",
        "plt.tight_layout()\n",
        "\n",
        "# 図4-6\n",
        "savefig(\"fig/pyssp_stft_tradeoff\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuuhtpxU_1Gb"
      },
      "source": [
        "### 逆短時間フーリエ変換による音声の復元"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbfwWruk_1Gb"
      },
      "outputs": [],
      "source": [
        "# 音声ファイルの読み込み\n",
        "sr, x = wavfile.read(ttslearn.util.example_audio_file())\n",
        "# 5 ミリ秒のフレームシフトを考えます\n",
        "frame_shift = int(sr * 0.005)\n",
        "n_fft = 2048\n",
        "\n",
        "# STFT\n",
        "X = librosa.stft(x.astype(np.float32), n_fft=n_fft, win_length=n_fft, hop_length=frame_shift, window=\"hann\")\n",
        "# ISTFT\n",
        "x_hat = librosa.istft(X, win_length=n_fft, hop_length=frame_shift, window=\"hann\")\n",
        "\n",
        "IPython.display.display(Audio(x.astype(np.float32), rate=sr))\n",
        "IPython.display.display(Audio(x_hat.astype(np.float32), rate=sr))\n",
        "\n",
        "fig, ax = plt.subplots(2, 1, figsize=(8,4), sharey=True)\n",
        "ax[0].set_title(\"Original speech\")\n",
        "ax[1].set_title(\"Reconstructed speech by ISTFT\")\n",
        "librosa.display.waveshow(x.astype(np.float32), sr, ax=ax[0])\n",
        "librosa.display.waveshow(x_hat.astype(np.float32), sr, ax=ax[1])\n",
        "\n",
        "for a in ax:\n",
        "    a.set_xlabel(\"Time [sec]\")\n",
        "    a.set_ylabel(\"Amplitude\")\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cb7DCeGq_1Gb"
      },
      "source": [
        "## 4.6 メルスペクトログラム"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-cqSRSV_1Gb"
      },
      "source": [
        "### メルフィルタバンク"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zw6gRjEB_1Gb"
      },
      "outputs": [],
      "source": [
        "sr = 16000\n",
        "n_fft = 2048\n",
        "n_mels = 8\n",
        "\n",
        "# 音声ファイルの読み込み\n",
        "sr, x = wavfile.read(ttslearn.util.example_audio_file())\n",
        "x = x.astype(np.float32)\n",
        "x = librosa.resample(x, sr, 16000)\n",
        "sr = 16000\n",
        "\n",
        "# 5 ミリ秒のフレームシフトを考えます\n",
        "frame_shift = int(sr * 0.005)\n",
        "# STFT\n",
        "X = librosa.stft(x, n_fft=n_fft, win_length=n_fft, hop_length=frame_shift, window=\"hann\")\n",
        "# 1 フレームを切り出す\n",
        "X_m = np.abs(X[:, 280])\n",
        "\n",
        "# メルフィルタバンク: n_mels 個のフィルタから構成されます\n",
        "melfb = librosa.filters.mel(sr, n_fft, n_mels=n_mels, norm=None)\n",
        "freq = librosa.fft_frequencies(sr, n_fft)\n",
        "\n",
        "# メルフィルタバンクを表示\n",
        "fig, ax = plt.subplots(n_mels+1, 2, figsize=(8,10), sharex=True)\n",
        "ax[0][0].plot(freq, np.ones_like(freq))\n",
        "ax[0][0].set_title(\"All pass filter\")\n",
        "ax[0][0].set_ylim(0,1.1)\n",
        "ax[0][1].plot(freq, X_m)\n",
        "ax[0][1].set_title(\"Input amplitude spectrum\")\n",
        "for idx, fb in enumerate(melfb):\n",
        "    ax[idx+1][0].plot(freq, fb)\n",
        "    ax[idx+1][0].set_title(f\"Filter {idx+1}\")\n",
        "    ax[idx+1][1].plot(freq, fb * X_m)\n",
        "    ax[idx+1][1].set_title(f\"Filtered amplitude {idx+1}\")\n",
        "\n",
        "for a,b in ax:\n",
        "    a.set_xlabel(\"Frequency [Hz]\")\n",
        "    b.set_xlabel(\"Frequency [Hz]\")\n",
        "    a.set_ylabel(\"Amplitude\")\n",
        "plt.tight_layout()\n",
        "\n",
        "# 図4-7\n",
        "savefig(\"fig/pyssp_melfb\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaRbIomr_1Gb"
      },
      "source": [
        "### メルスペクトログラムの計算"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jT1weAQK_1Gb"
      },
      "outputs": [],
      "source": [
        "# 音声ファイルの読み込み\n",
        "sr, x = wavfile.read(ttslearn.util.example_audio_file())\n",
        "# 5 ミリ秒のフレームシフトを考えます\n",
        "frame_shift = int(sr * 0.005)\n",
        "n_fft = 2048\n",
        "\n",
        "# スペクトログラム\n",
        "X = librosa.stft(x.astype(np.float32), n_fft=n_fft, hop_length=frame_shift)\n",
        "\n",
        "# 80 次元のメルスペクトログラム\n",
        "n_mels = 80\n",
        "melfb = librosa.filters.mel(sr, n_fft, n_mels=n_mels)\n",
        "melspec = librosa.amplitude_to_db(np.dot(melfb, np.abs(X)), ref=np.max)\n",
        "\n",
        "# 比較用の対数振幅スペクトログラム\n",
        "logX = librosa.amplitude_to_db(np.abs(X), ref=np.max)\n",
        "\n",
        "fig, ax = plt.subplots(2, 1, figsize=(8,6))\n",
        "ax[0].set_title(\"Spectrogram\")\n",
        "ax[1].set_title(\"80-dim Mel-spectrogram\")\n",
        "mesh = librosa.display.specshow(logX, hop_length=frame_shift, sr=sr, cmap=cmap, x_axis=\"time\", y_axis=\"hz\", ax=ax[0])\n",
        "fig.colorbar(mesh, ax=ax[0], format=\"%+2.f dB\")\n",
        "mesh.set_clim(-80, 0)\n",
        "mesh = librosa.display.specshow(melspec, hop_length=frame_shift, sr=sr, cmap=cmap, x_axis=\"time\", y_axis=\"mel\",ax=ax[1])\n",
        "fig.colorbar(mesh, ax=ax[1], format=\"%+2.f dB\")\n",
        "mesh.set_clim(-80, 0)\n",
        "\n",
        "for a in ax:\n",
        "    a.set_ylim(0, 8000)\n",
        "    a.set_xlabel(\"Time [sec]\")\n",
        "    a.set_ylabel(\"Frequency [Hz]\")\n",
        "plt.tight_layout()\n",
        "\n",
        "# 図4-8\n",
        "savefig(\"fig/pyssp_melspectrogram\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNpQn1VO_1Gb"
      },
      "source": [
        "## 4.6 Griffin-Lim のアルゴリズムに基づく位相復元"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOzQIvm2_1Gc"
      },
      "outputs": [],
      "source": [
        "# 音声ファイルの読み込み\n",
        "sr, x = wavfile.read(ttslearn.util.example_audio_file())\n",
        "# 5 ミリ秒のフレームシフトを考えます\n",
        "frame_shift = int(sr * 0.005)\n",
        "n_fft = 2048\n",
        "\n",
        "# 振幅スペクトログラム\n",
        "X = np.abs(librosa.stft(x.astype(np.float32), n_fft=n_fft, hop_length=frame_shift))\n",
        "\n",
        "y1 = librosa.griffinlim(X, hop_length=frame_shift, n_iter=1)\n",
        "y2 = librosa.griffinlim(X, hop_length=frame_shift, n_iter=100)\n",
        "\n",
        "# オーディオプレイヤーの表示\n",
        "IPython.display.display(Audio(y1, rate=sr))\n",
        "IPython.display.display(Audio(y2, rate=sr))\n",
        "IPython.display.display(Audio(x, rate=sr))\n",
        "\n",
        "fig, ax = plt.subplots(3, 1, figsize=(8,6), sharey=True)\n",
        "ax[0].set_title(\"Griffin-Lim # of iteration: 1\")\n",
        "ax[1].set_title(\"Griffin-Lim # of iteration: 100\")\n",
        "ax[2].set_title(\"Natural speech\")\n",
        "librosa.display.waveshow(y1, sr=sr, ax=ax[0])\n",
        "librosa.display.waveshow(y2, sr=sr, ax=ax[1])\n",
        "librosa.display.waveshow(x.astype(np.float32), sr=sr, ax=ax[2])\n",
        "\n",
        "for a in ax:\n",
        "    a.set_xlabel(\"Time [sec]\")\n",
        "    a.set_ylabel(\"Amplitude\")\n",
        "plt.tight_layout()\n",
        "\n",
        "# 図4-9\n",
        "savefig(\"fig/pyssp_griffin_lim\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjNLEeI0_1Gc"
      },
      "source": [
        "### 瞬時周波数の可視化 (bonus)\n",
        "\n",
        "Griffin-Limのアルゴリズムは、位相復元手法です。合成音声と自然音声の瞬時位相（位相の時間微分）を比較することで、位相復元が期待通り行われているかを視覚的に確認できます。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsw2yuL9_1Gc"
      },
      "outputs": [],
      "source": [
        "n_fft = 1024\n",
        "hop_length = n_fft // 4\n",
        "fig, ax = plt.subplots(1, 3, figsize=(10,5), sharex=True)\n",
        "\n",
        "C = librosa.stft(y1, n_fft=n_fft, hop_length=hop_length)\n",
        "ifreq = np.angle(C[:, 1:] * np.conjugate(C[:, :-1]))\n",
        "mesh = librosa.display.specshow(ifreq, cmap=cmap, ax=ax[0], x_axis=\"time\", y_axis=\"hz\", sr=sr, hop_length=hop_length)\n",
        "fig.colorbar(mesh, ax=ax[0])\n",
        "ax[0].set_title(\"GL # of iteration: 1\")\n",
        "\n",
        "C = librosa.stft(y2, n_fft=n_fft, hop_length=hop_length)\n",
        "ifreq = np.angle(C[:, 1:] * np.conjugate(C[:, :-1]))\n",
        "mesh = librosa.display.specshow(ifreq, cmap=cmap, ax=ax[1], x_axis=\"time\", y_axis=\"hz\", sr=sr, hop_length=hop_length)\n",
        "fig.colorbar(mesh, ax=ax[1])\n",
        "ax[1].set_title(\"GL # of iteration: 100\")\n",
        "\n",
        "C = librosa.stft(x.astype(np.float32), n_fft=n_fft, hop_length=hop_length)\n",
        "ifreq = np.angle(C[:, 1:] * np.conjugate(C[:, :-1]))\n",
        "mesh = librosa.display.specshow(ifreq, cmap=cmap, ax=ax[2], x_axis=\"time\", y_axis=\"hz\", sr=sr, hop_length=hop_length)\n",
        "fig.colorbar(mesh, ax=ax[2])\n",
        "ax[2].set_title(\"Natural speech\")\n",
        "\n",
        "for a in ax:\n",
        "    # あとでラベルを付け直すので、ここでは消しておく\n",
        "    a.set_ylabel(\"\")\n",
        "\n",
        "ax[0].set_ylabel(\"Frequency [Hz]\")\n",
        "for a in ax:\n",
        "    a.set_xlim(1.5, 3.0)\n",
        "    a.set_ylim(0, 4000)\n",
        "    a.set_xlabel(\"Time [sec]\")\n",
        "    a.set_xticks([1.5, 2.0, 2.5, 3.0])\n",
        "\n",
        "plt.tight_layout()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}